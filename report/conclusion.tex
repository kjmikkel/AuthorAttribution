
% [Conclusions are very important. Do not expect that the reader remembers everything you told him/her.
% Having stated the definitions, you can now be more specific that  in the introduction]
% * Overview what this work was about.
% * Main results and contributions
% * Comments on importance or
% * Tips for practical use [how your results or experience can help someone in practice or
%     another researcher to use your simulator or avoid pitfalls]
% * Future work. Reinforce the importance of work, but avoid giving out your ideas].

\section{Conclusion}
\label{conclusion}

\subsection{Summery}
I have in this report investigated possible methods for Authorship Attribution for Internet forums, and discussed the advantages and disadvantages of each of these methods. I have given a detailed explaination of how the $n$-gram method proposed in \cite{nr4} works, as well as an introduction to Good-Turing smoothing. I have designed and run tests designed to expose whether the algorithm could be used on Internet forums, and interpreted the returend results.  

\subsection{Results}
From section \ref{interpretation} I can conclude that the algorithm described in \cite{nr4} cannot be used with the Good-Turing smoothing for identifying user on Internet forums. The results in section \ref{tests} that when authors with few $n$-grams (i.e. has written few short posts) appear in the corpora, there is a high probability that they will be attributed as the author\footnote{And even then, there is no guarantee that they will be attributed the posts that they themselves have written}.\\

A clear lesson from \cite{nr4} is therefore that any $n$-gram algorithm that has to be used for Internet forums must be robust enough to give texts a proportionate probability based on the $n$-grams, so that author corporas of widely different sizes can be tested together, and still give meaningful results. 

\subsection{Future work}

\begin{itemize}
\item Since it is likely that many of the wrong attributions are caused by the way that Good-Turing smoothing assigns a far too high probability for the $n$-grams that does not appear in small corporas, it would be interesting to see whether using another smoothing technique (\cite{nr4} also proposes Witten-Bell smoothing) would improve the results.

\item While this report has produced bad results when it comes to texts written in the Danish language, it would be interesting to see the results of using it on different languages --- such as English, Greek or Chinese.

\item This report was made using 3-grams with characters as the token/gram, and it would therefore be interesting to see the results of a different configuration --- such as using words as the token/gram, and trying the entire spectrum of 3-6 grams. 

\item Attempt to use the a modified algorithm on a larger corpora --- preferably from an active forum with a large number of users. 

\item Turn a working algorithm into a plug-in for a forum, in order to field test its value in a real situation. Here it would especially be interesting to study the reactions from both forum users as well as the moderators. This should be done in order to study the social dimension of bringing Author Attribution to the Internet.
\end{itemize}  

\subsubsection*{Acknowledgements}
I would like to thank Johan Brinck for giving me the forum data that I have been analysing.
